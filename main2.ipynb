{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiimkhang/dog_breed_classification/blob/main/main2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = \"dog_breed_classification/small_dataset.zip\"\n",
        "if not os.path.isdir('small_dataset'):\n",
        "    !git clone https://github.com/hiimkhang/dog_breed_classification\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n"
      ],
      "metadata": {
        "id": "IOx9I8nYEPrq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eXeGmCEXENKL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.hub import load_state_dict_from_url\n",
        "except ImportError:\n",
        "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.skip_add = nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        #out += identity\n",
        "        out = self.skip_add.add(out, identity)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.skip_add = nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        #out += identity\n",
        "        out = self.skip_add.add(out, identity)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        self.quant = QuantStub()\n",
        "        self.dequant = DeQuantStub()\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
        "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.quant(x) # add quant\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        x = self.dequant(x) # add dequant\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(\n",
        "    arch: str,\n",
        "    block: Type[Union[BasicBlock, Bottleneck]],\n",
        "    layers: List[int],\n",
        "    pretrained: bool,\n",
        "    progress: bool,\n",
        "    **kwargs: Any\n",
        ") -> ResNet:\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50_quantizable(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pw9jrTJEENKP"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "root = './small_dataset'\n",
        "img_size = 224\n",
        "\n",
        "train_batch_size = 8\n",
        "eval_batch_size = 8\n",
        "num_workers = 2\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                std=(0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                std=(0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "train_set = datasets.ImageFolder(root=os.path.join(root, 'train'), transform=train_transform)\n",
        "test_set = datasets.ImageFolder(root=os.path.join(root, 'valid'), transform=test_transform)\n",
        "\n",
        "train_sampler = torch.utils.data.RandomSampler(train_set)\n",
        "test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set,\n",
        "                        batch_size=train_batch_size,\n",
        "                        sampler=train_sampler,\n",
        "                        num_workers=num_workers)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_set,\n",
        "                        batch_size=eval_batch_size,\n",
        "                        sampler=test_sampler,\n",
        "                        num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp32_model = resnet50_quantizable(pretrained=True)"
      ],
      "metadata": {
        "id": "PGd4cwSNlMT5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xnAT7dLMENKP"
      },
      "outputs": [],
      "source": [
        "cuda_device = torch.device(\"cuda:0\")\n",
        "cpu_device = torch.device(\"cpu:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC3NwYzrENKQ",
        "outputId": "17c41508-a37d-4f7a-97e2-8512e5ce54ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([8, 3, 224, 224])\n",
            "Number of classes (out_features): 3\n",
            "in_channels:  3\n"
          ]
        }
      ],
      "source": [
        "batch_inputs, batch_targets = next(iter(train_loader))\n",
        "\n",
        "in_channels = batch_inputs.shape[1]     # number of channels of input images\n",
        "out_features = len(train_set.classes)\n",
        "\n",
        "print(\"Input tensor shape:\", batch_inputs.shape)\n",
        "print(\"Number of classes (out_features):\", out_features)\n",
        "print(\"in_channels: \", in_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OA8dfHW7ENKR"
      },
      "outputs": [],
      "source": [
        "def modifyLayers(model: torch.nn.Module, in_channels: int, out_features: int):\n",
        "    # modify the first convolutional layer, in_channels = input tensor channels\n",
        "    model.conv1 = torch.nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # modify the last fc layer, out_features = number of classes\n",
        "    model.fc = torch.nn.Linear(model.fc.in_features, out_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "IXD0BEQ5ENKR"
      },
      "outputs": [],
      "source": [
        "def test(model: torch.nn.Module, loaders: DataLoader):\n",
        "    # Test the model\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in tqdm(loaders, total=len(loaders)):\n",
        "            images = images.to('cpu')\n",
        "            labels = labels.to('cpu')\n",
        "\n",
        "            # Quantize the input data (images)\n",
        "            # images_quantized = torch.quantization.quantize_data(images, scale=1.0, zero_point=0, dtype=torch.quint8)\n",
        "            test_output = model(images)\n",
        "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
        "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
        "\n",
        "    print(f\"Test Accuracy of the model on the {len(loaders) * loaders.batch_size} test images: {accuracy:.2f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: nn.Module,\n",
        "               train_loader: DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> tuple[float, float]:\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_accuracy = 0., 0.\n",
        "\n",
        "    for batch, (image, label) in enumerate(train_loader):\n",
        "        image, label = image.to(device), label.to(device)\n",
        "\n",
        "        label_pred = model(image) # forward pass\n",
        "\n",
        "        loss = loss_fn(label_pred, label) # compute loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad() # zero param gradients\n",
        "\n",
        "        loss.backward() # backward pass\n",
        "\n",
        "        optimizer.step() # update parameters\n",
        "\n",
        "        y_pred_labels = torch.argmax(torch.softmax(label_pred, dim=1), dim=1) # compute accuracy\n",
        "        train_accuracy += (y_pred_labels == label).sum().item() / len(label_pred)\n",
        "\n",
        "    avg_loss, avg_acc = train_loss/len(train_loader), train_accuracy/len(train_loader)\n",
        "    print(f\"Train loss: {avg_loss:.4f} | Train accuracy: {avg_acc:.4f}\", end=' | ')\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "QtNduHml6xYe"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_step(model: nn.Module,\n",
        "              test_loader: DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              device: torch.device) -> tuple[float, float]:\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, test_accuracy = 0., 0.\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (image, label) in enumerate(test_loader):\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            label_pred_logits = model(image) # forward pass\n",
        "\n",
        "            loss = loss_fn(label_pred_logits, label) # compute loss\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            label_pred_labels = label_pred_logits.argmax(dim=1) # compute accuracy\n",
        "            test_accuracy += (label_pred_labels == label).sum().item() / len(label_pred_labels)\n",
        "\n",
        "    avg_loss, avg_acc = test_loss/len(test_loader), test_accuracy/len(test_loader)\n",
        "    print(f\"Test loss: {avg_loss:.4f} | Test accuracy: {avg_acc:.4f}\")\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "Xk5hrjYr7_9d"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module,\n",
        "          train_loader: DataLoader,\n",
        "          test_loader: DataLoader,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> dict[str, list]:\n",
        "    global results_info\n",
        "    model.to(device)\n",
        "\n",
        "    results = {\n",
        "        'Train loss': [],\n",
        "        'Train accuracy': [],\n",
        "        'Test loss': [],\n",
        "        'Test accuracy': [],\n",
        "    }\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(),\n",
        "                            1e-3,\n",
        "                            momentum=0.9,\n",
        "                            weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                     milestones=[100, 150],\n",
        "                                                     gamma=0.1,\n",
        "                                                     last_epoch=-1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}: \", end=\"\")\n",
        "\n",
        "        train_loss, train_acc = train_step(model, train_loader, loss_fn, optimizer, device)\n",
        "        test_loss, test_acc = eval_step(model, test_loader, loss_fn, device)\n",
        "\n",
        "        results['Train loss'].append(train_loss)\n",
        "        results['Train accuracy'].append(train_acc)\n",
        "        results['Test loss'].append(test_loss)\n",
        "        results['Test accuracy'].append(test_acc)\n",
        "\n",
        "        scheduler.step()\n",
        "        # Write model into log.txt\n",
        "        # with open('log.txt', 'w') as f:\n",
        "        #     f.write(f\"Model: {model}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0V6otwHR8pt5"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Use an original resnet50 pretrained model to train and evaluate\n",
        "# Can be used for later comparisons\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "modifyLayers(model=resnet50,\n",
        "             in_channels=in_channels,\n",
        "             out_features=out_features) # modify first conv1 and last fc layer according to dataset\n",
        "\n",
        "resnet50_result = train_model(model=resnet50,\n",
        "            train_loader=train_loader,\n",
        "            test_loader=test_loader,\n",
        "            epochs=10,\n",
        "            device=cuda_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diOlDL-dCiTo",
        "outputId": "d0220e32-cf24-4656-a17d-e635a20d8192"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10: Train loss: 1.1376 | Train accuracy: 0.4022 | Test loss: 1.1336 | Test accuracy: 0.4167\n",
            "\n",
            "Epoch 2/10: Train loss: 0.8559 | Train accuracy: 0.5734 | Test loss: 0.7554 | Test accuracy: 0.5979\n",
            "\n",
            "Epoch 3/10: Train loss: 0.7620 | Train accuracy: 0.6522 | Test loss: 0.7198 | Test accuracy: 0.6083\n",
            "\n",
            "Epoch 4/10: Train loss: 0.6782 | Train accuracy: 0.7038 | Test loss: 0.6984 | Test accuracy: 0.6437\n",
            "\n",
            "Epoch 5/10: Train loss: 0.4675 | Train accuracy: 0.7989 | Test loss: 0.9069 | Test accuracy: 0.6396\n",
            "\n",
            "Epoch 6/10: Train loss: 0.4062 | Train accuracy: 0.8424 | Test loss: 0.8373 | Test accuracy: 0.6813\n",
            "\n",
            "Epoch 7/10: Train loss: 0.4077 | Train accuracy: 0.8397 | Test loss: 1.1912 | Test accuracy: 0.5833\n",
            "\n",
            "Epoch 8/10: Train loss: 0.2024 | Train accuracy: 0.9321 | Test loss: 1.3536 | Test accuracy: 0.5812\n",
            "\n",
            "Epoch 9/10: Train loss: 0.2700 | Train accuracy: 0.8940 | Test loss: 1.4192 | Test accuracy: 0.5667\n",
            "\n",
            "Epoch 10/10: Train loss: 0.3090 | Train accuracy: 0.8832 | Test loss: 1.3048 | Test accuracy: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AWXQDC0ENKS",
        "outputId": "62e601b5-98f1-4211-d989-cc4c98030cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10: Train loss: 1.1332 | Train accuracy: 0.3886 | Test loss: 0.9995 | Test accuracy: 0.4167\n",
            "\n",
            "Epoch 2/10: Train loss: 0.9393 | Train accuracy: 0.5462 | Test loss: 0.8415 | Test accuracy: 0.5521\n",
            "\n",
            "Epoch 3/10: Train loss: 0.6641 | Train accuracy: 0.6685 | Test loss: 0.7376 | Test accuracy: 0.7229\n",
            "\n",
            "Epoch 4/10: Train loss: 0.5436 | Train accuracy: 0.7527 | Test loss: 0.7688 | Test accuracy: 0.6604\n",
            "\n",
            "Epoch 5/10: Train loss: 0.4279 | Train accuracy: 0.8234 | Test loss: 0.9490 | Test accuracy: 0.6750\n",
            "\n",
            "Epoch 6/10: Train loss: 0.4583 | Train accuracy: 0.7853 | Test loss: 1.0415 | Test accuracy: 0.6021\n",
            "\n",
            "Epoch 7/10: Train loss: 0.3059 | Train accuracy: 0.8723 | Test loss: 1.1175 | Test accuracy: 0.6562\n",
            "\n",
            "Epoch 8/10: Train loss: 0.2783 | Train accuracy: 0.8967 | Test loss: 0.9577 | Test accuracy: 0.6500\n",
            "\n",
            "Epoch 9/10: Train loss: 0.2607 | Train accuracy: 0.8995 | Test loss: 1.0095 | Test accuracy: 0.6604\n",
            "\n",
            "Epoch 10/10: Train loss: 0.1927 | Train accuracy: 0.9158 | Test loss: 1.2022 | Test accuracy: 0.6396\n"
          ]
        }
      ],
      "source": [
        "# Use customized resnet50 pretrained model to train and evaluate\n",
        "# This quantizable model later will be used to quantize into the compressed int8 param model\n",
        "\n",
        "resnet50_quantizable = resnet50_quantizable(pretrained=True)\n",
        "\n",
        "modifyLayers(model=resnet50_quantizable,\n",
        "             in_channels=in_channels,\n",
        "             out_features=out_features) # modify first conv1 and last fc layer according to dataset\n",
        "\n",
        "resnet50_quantizable_result = train_model(model=resnet50_quantizable,\n",
        "            train_loader=train_loader,\n",
        "            test_loader=test_loader,\n",
        "            epochs=10,\n",
        "            device=cuda_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POzjSsgeENKS",
        "outputId": "7e994079-4727-450c-eee5-8bba827fcbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50: Test loss: 1.3048 | Test accuracy: 0.6250\n",
            "Quantizable ResNet50: Test loss: 1.2022 | Test accuracy: 0.6396\n"
          ]
        }
      ],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() # Loss function for evaluation\n",
        "\n",
        "# Use the original resnet50 and customized quantizable resnet50 to evaluate on the test\n",
        "print(\"ResNet50: \", end=\"\")\n",
        "resnet50_eval = eval_step(resnet50, test_loader, loss_fn, cpu_device)\n",
        "\n",
        "print(\"Quantizable ResNet50: \", end=\"\")\n",
        "resnet50_quantizable_eval = eval_step(resnet50_quantizable, test_loader, loss_fn, cpu_device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSNNYCw_IjcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKViWVAQENKS",
        "outputId": "3898ee2c-e6ef-47aa-9adc-0c4b89324f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:11<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 96 test images: 0.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test(float_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(float_model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwGnLAzWmgPX",
        "outputId": "f5c628af-60ac-47aa-d7df-e8302b80b608"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46/46 [00:42<00:00,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 368 test images: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuPBo4GaENKT",
        "outputId": "80bbcd69-cbad-4052-d285-25b8fb8896e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:31<00:00,  2.65s/it]\n"
          ]
        }
      ],
      "source": [
        "# Our initial baseline model which is FP32\n",
        "model_fp32 = float_model\n",
        "model_fp32.eval()\n",
        "\n",
        "# Sets the backend for x86\n",
        "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "model_fp32 = torch.quantization.fuse_modules(model_fp32, [['conv1', 'bn1', 'relu']], inplace=True)\n",
        "\n",
        "# Prepares the model for the next step i.e. calibration.\n",
        "# Inserts observers in the model that will observe the activation tensors during calibration\n",
        "model_fp32_prepared = torch.quantization.prepare(model_fp32, inplace = False)\n",
        "\n",
        "# Calibrate over the train dataset. This determines the quantization params for activation.\n",
        "# I used 1000 images of Imagenet train dataset for calibration.\n",
        "for batch, target in tqdm(test_loader, total=len(test_loader)):\n",
        "    model_fp32_prepared(batch)\n",
        "\n",
        "# Converts the model to a quantized model(int8)\n",
        "model_quantized = torch.quantization.convert(model_fp32_prepared) # Quantize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ayRlE_yHENKT"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('save_models'):\n",
        "    os.makedirs('save_models', exist_ok=True)\n",
        "\n",
        "torch.save(model_quantized.state_dict(), \"./save_models/resnet50_trained.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-fE2A7fENKT",
        "outputId": "98b60d8f-3a9e-4246-ddcc-2a12e42d1ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:08<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 96 test images: 0.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test(model_quantized, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDbx-N6WENKT",
        "outputId": "e69f7092-a541-4812-e47c-10b657679a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46/46 [00:33<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 368 test images: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test(model_quantized, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "eval_step(model_quantized, train_loader, loss_fn, cpu_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzgUj6ujYkoV",
        "outputId": "a6239b5d-3024-445f-d556-5afb94aef941"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.26493363851762336, 0.9021739130434783)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_step(float_model, train_loader, loss_fn, cpu_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1rxhWpOiBp2",
        "outputId": "1d0b9ff0-0a15-4b06-d845-9f9647370ab7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.24205996015149614, 0.9130434782608695)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_step(float_model, test_loader, loss_fn, cpu_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_YjwyRKn3Ob",
        "outputId": "a8056987-2f30-4792-b3ab-72c272950119"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9771170268456141, 0.5875)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_step(model_quantized, test_loader, loss_fn, cpu_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4cPm2Q4n6R5",
        "outputId": "2b2555f1-3b53-44ec-c34a-ce31d710e9a9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9633230070273081, 0.5770833333333333)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_step(resnet50, test_loader, loss_fn, cpu_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCPYSrzviGF7",
        "outputId": "3ab2f398-58ae-497a-dfe1-35788e3a7b1e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.2141008414328098, 0.6229166666666667)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(pretrained=True).to(cuda_device)\n",
        "modifyLayers(resnet50, in_channels, out_features)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet50.parameters(),\n",
        "                          1e-3,\n",
        "                          momentum=0.9,\n",
        "                          weight_decay=1e-4)\n",
        "\n",
        "train_model(resnet50, train_loader, test_loader, 10, cuda_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Any7t0gVnvIF",
        "outputId": "ea6308bf-d76c-4e88-f425-e3c481698baf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:05<00:51,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10 | Train loss: 1.0217 | Train accuracy: 0.4755 | Test loss: 0.8912 | Test accuracy: 0.5979\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:11<00:44,  5.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/10 | Train loss: 0.9238 | Train accuracy: 0.5679 | Test loss: 0.9589 | Test accuracy: 0.6312\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:16<00:36,  5.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/10 | Train loss: 0.7231 | Train accuracy: 0.6766 | Test loss: 0.9789 | Test accuracy: 0.5167\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:21<00:32,  5.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/10 | Train loss: 0.5464 | Train accuracy: 0.7418 | Test loss: 0.6901 | Test accuracy: 0.6083\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:26<00:26,  5.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/10 | Train loss: 0.4955 | Train accuracy: 0.7880 | Test loss: 0.7397 | Test accuracy: 0.6646\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:32<00:21,  5.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/10 | Train loss: 0.3681 | Train accuracy: 0.8179 | Test loss: 0.8258 | Test accuracy: 0.6437\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:37<00:15,  5.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/10 | Train loss: 0.2726 | Train accuracy: 0.8967 | Test loss: 0.9245 | Test accuracy: 0.6708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:42<00:10,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/10 | Train loss: 0.2363 | Train accuracy: 0.9103 | Test loss: 1.0156 | Test accuracy: 0.6188\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:47<00:05,  5.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/10 | Train loss: 0.2658 | Train accuracy: 0.9022 | Test loss: 1.3628 | Test accuracy: 0.6229\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:52<00:00,  5.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/10 | Train loss: 0.2442 | Train accuracy: 0.9103 | Test loss: 1.2141 | Test accuracy: 0.6229\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_step(resnet50, test_loader, loss_fn, cuda_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJvBenvy_5DX",
        "outputId": "451a5f8a-e0eb-41ff-98ab-70961dc85ee2"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3799385627110798, 0.47500000000000003)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(resnet50, train_loader, loss_fn, optimizer, cuda_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17kP6IkkAGy8",
        "outputId": "447fe1a4-ff15-428c-a1b8-63f5616a20d8"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46/46 [00:04<00:00,  9.61it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0995179829390154, 0.41847826086956524)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(resnet50, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfzM_jPEoTze",
        "outputId": "16417e30-2c63-4d35-e6ea-3bdfa2c69a63"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46/46 [00:59<00:00,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 368 test images: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(resnet50, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_H9IM6yowV7",
        "outputId": "7e966e4b-c49a-4806-970f-cd26f9b20928"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:15<00:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 96 test images: 0.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our initial baseline model which is FP32\n",
        "model_fp32 = resnet50\n",
        "model_fp32.eval()\n",
        "\n",
        "# Sets the backend for x86\n",
        "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "model_fp32 = torch.quantization.fuse_modules(model_fp32, [['conv1', 'bn1', 'relu']], inplace=True)\n",
        "\n",
        "# # Prepares the model for the next step i.e. calibration.\n",
        "# # Inserts observers in the model that will observe the activation tensors during calibration\n",
        "# model_fp32_prepared = torch.quantization.prepare(model_fp32, inplace = False)\n",
        "\n",
        "# # Calibrate over the train dataset. This determines the quantization params for activation.\n",
        "# # I used 1000 images of Imagenet train dataset for calibration.\n",
        "# for batch, target in tqdm(test_loader, total=len(test_loader)):\n",
        "#     model_fp32_prepared(batch)\n",
        "\n",
        "# # Converts the model to a quantized model(int8)\n",
        "# model_quantized = torch.quantization.convert(model_fp32_prepared) # Quantize the model"
      ],
      "metadata": {
        "id": "j4YTom7To87D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6OyNe8HpLRY",
        "outputId": "9704fe4a-4a97-49cf-ff63-15410004aa6c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}